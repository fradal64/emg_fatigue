{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:03:10.255476: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 16:03:10.255970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-13 16:03:10.260080: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-13 16:03:10.268274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744552990.285850  944033 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744552990.291104  944033 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744552990.302222  944033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744552990.302243  944033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744552990.302245  944033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744552990.302246  944033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-13 16:03:10.305921: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[32m2025-04-13 16:03:12.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue\u001b[0m\n",
      "/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutex6unlockEv']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZN3tsl7strings13safe_strtou64ESt17basic_string_viewIcSt11char_traitsIcEEPm']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from emg_fatigue.utils.load_emg_data import load_all_participant_data\n",
    "from emg_fatigue.utils.process_emg_data import process_all_participant_data\n",
    "from emg_fatigue.utils.create_loocv_dataset import create_loocv_dataset\n",
    "from emg_fatigue.modeling.train import train_model\n",
    "from emg_fatigue.modeling.evaluate import evaluate_model\n",
    "from emg_fatigue.modeling.build.rnn_model import build_lstm_model\n",
    "from emg_fatigue.modeling.build.mlp_model import build_mlp_model\n",
    "from emg_fatigue.modeling.build.transformer_model import build_transformer_model\n",
    "from emg_fatigue.modeling.build.gru_model import build_gru_model\n",
    "from emg_fatigue.plots.visualize_model_predictions import visualize_model_predictions\n",
    "from emg_fatigue.config import BATCH_SIZE, PADDING_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-13 16:03:18.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mProcessing data for datasets...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  Processing train set (9 participants)...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  Processing val set (2 participants)...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  Processing test set (1 participants)...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1m\n",
      "Found 513 frequency bins (features).\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mMaximum sequence length across all sets: 249.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mApplying SpecAugment data augmentation to training data...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m271\u001b[0m - \u001b[1m  Time masking: param=10, masks=1\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1m  Frequency masking: param=10, masks=1\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:18.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m273\u001b[0m - \u001b[1m  Augmentation factor: 1\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:03:18.669471: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-13 16:03:19.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m294\u001b[0m - \u001b[1m  Data augmentation complete. Training samples: 144 → 288\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m299\u001b[0m - \u001b[1mPadding sequences...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1m  Padded Train data shape: X=(288, 249, 513), y=(288, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1m  Padded Val data shape: X=(32, 249, 513), y=(32, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1m  Padded Test data shape: X=(16, 249, 513), y=(16, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m347\u001b[0m - \u001b[1m  Standardized Training data shape: X=(288, 249, 513), y=(288, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1m  Standardized Validation data shape: X=(32, 249, 513), y=(32, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1m  Standardized Test data shape: X=(16, 249, 513), y=(16, 249)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m358\u001b[0m - \u001b[1mCreating TensorFlow Datasets...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_tf_dataset\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1m    Dataset created successfully with 288 sequences.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_tf_dataset\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1m    Dataset created successfully with 32 sequences.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_tf_dataset\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1m    Dataset created successfully with 16 sequences.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1m\n",
      "Dataset creation complete.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m371\u001b[0m - \u001b[1m  Input Shape for Model: (249, 513)\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.utils.create_loocv_dataset\u001b[0m:\u001b[36mcreate_loocv_dataset\u001b[0m:\u001b[36m372\u001b[0m - \u001b[1m  Output Shape (Sequence Length): 249\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_all_participant_data()\n",
    "processed_data = process_all_participant_data(participant_data=raw_data)\n",
    "\n",
    "\n",
    "# --- Create LOO-CV Datasets ---\n",
    "all_participant_ids = list(processed_data.keys())\n",
    "train_ids = all_participant_ids[:-3] \n",
    "val_ids = all_participant_ids[-3:-1]\n",
    "test_ids = [all_participant_ids[-1]]\n",
    "\n",
    "train_ds, val_ds, test_ds, input_shape, output_shape, norm_mean, norm_std = create_loocv_dataset(\n",
    "    processed_data=processed_data,\n",
    "    train_participant_ids=train_ids,\n",
    "    validation_participant_ids=val_ids,\n",
    "    test_participant_ids=test_ids,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    padding_value=PADDING_VALUE,\n",
    "    normalize=True,\n",
    "    augment=True,\n",
    "    time_param=10,\n",
    "    time_masks=1,\n",
    "    freq_param=10,\n",
    "    freq_masks=1,\n",
    "    augmentation_factor=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-13 16:03:19.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.modeling.build.transformer_model\u001b[0m:\u001b[36mbuild_transformer_model\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mBuilding Transformer model for test participant: P012\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mModel will be saved to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\u001b[0m\n",
      "\u001b[32m2025-04-13 16:03:19.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mStarting model training for up to 200 epochs...\u001b[0m\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lg519/.cache/pypoetry/virtualenvs/emg-fatigue-YbMeuwX9-py3.12/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'squeeze_output' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1998.8115 - mae: 31.9879\n",
      "Epoch 1: val_loss improved from inf to 1807.94666, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 556ms/step - loss: 1990.3546 - mae: 31.9651 - val_loss: 1807.9467 - val_mae: 32.1337 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1666.9639 - mae: 30.4037\n",
      "Epoch 2: val_loss improved from 1807.94666 to 1653.90259, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 1665.8943 - mae: 30.4151 - val_loss: 1653.9026 - val_mae: 31.0661 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1530.9690 - mae: 29.2688\n",
      "Epoch 3: val_loss improved from 1653.90259 to 1496.73535, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 1529.8800 - mae: 29.2362 - val_loss: 1496.7354 - val_mae: 28.1316 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1378.3922 - mae: 25.8147\n",
      "Epoch 4: val_loss improved from 1496.73535 to 1338.08240, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - loss: 1377.0752 - mae: 25.7769 - val_loss: 1338.0824 - val_mae: 25.4537 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1230.1693 - mae: 23.6650\n",
      "Epoch 5: val_loss improved from 1338.08240 to 1185.21021, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 1228.5789 - mae: 23.6642 - val_loss: 1185.2102 - val_mae: 24.0354 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1091.1185 - mae: 22.3380\n",
      "Epoch 6: val_loss improved from 1185.21021 to 1038.07324, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 1089.4414 - mae: 22.3321 - val_loss: 1038.0732 - val_mae: 22.4481 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 955.5477 - mae: 20.8702\n",
      "Epoch 7: val_loss improved from 1038.07324 to 904.06030, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 954.0319 - mae: 20.8669 - val_loss: 904.0603 - val_mae: 21.0653 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 834.5339 - mae: 19.6120\n",
      "Epoch 8: val_loss improved from 904.06030 to 790.77039, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 833.1322 - mae: 19.6100 - val_loss: 790.7704 - val_mae: 19.8833 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 734.1409 - mae: 18.5627\n",
      "Epoch 9: val_loss improved from 790.77039 to 703.13715, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 733.0553 - mae: 18.5647 - val_loss: 703.1371 - val_mae: 18.9693 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 654.3391 - mae: 17.6878\n",
      "Epoch 10: val_loss improved from 703.13715 to 631.06641, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 653.2668 - mae: 17.6827 - val_loss: 631.0664 - val_mae: 17.8065 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 575.5831 - mae: 16.2679\n",
      "Epoch 11: val_loss improved from 631.06641 to 624.76453, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 576.8130 - mae: 16.2930 - val_loss: 624.7645 - val_mae: 17.7531 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 693.8583 - mae: 19.3035\n",
      "Epoch 12: val_loss improved from 624.76453 to 602.22876, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 689.4653 - mae: 19.3499 - val_loss: 602.2288 - val_mae: 18.4441 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 565.9293 - mae: 16.8407\n",
      "Epoch 13: val_loss improved from 602.22876 to 587.18640, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 566.1221 - mae: 16.8467 - val_loss: 587.1864 - val_mae: 17.6943 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 534.5350 - mae: 16.0375\n",
      "Epoch 14: val_loss improved from 587.18640 to 553.83514, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 534.4669 - mae: 16.0489 - val_loss: 553.8351 - val_mae: 17.1300 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 487.2574 - mae: 15.2038\n",
      "Epoch 15: val_loss improved from 553.83514 to 512.21289, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 485.6894 - mae: 15.1813 - val_loss: 512.2129 - val_mae: 15.8838 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 454.6180 - mae: 14.6384\n",
      "Epoch 16: val_loss improved from 512.21289 to 453.00446, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 454.9013 - mae: 14.6773 - val_loss: 453.0045 - val_mae: 15.0073 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 427.9870 - mae: 13.9811\n",
      "Epoch 17: val_loss improved from 453.00446 to 417.26770, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 427.4714 - mae: 14.0016 - val_loss: 417.2677 - val_mae: 14.6781 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 379.7163 - mae: 13.3141\n",
      "Epoch 18: val_loss did not improve from 417.26770\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 379.0361 - mae: 13.3178 - val_loss: 437.7719 - val_mae: 14.7124 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 382.8835 - mae: 13.3917\n",
      "Epoch 19: val_loss improved from 417.26770 to 400.56329, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 383.0309 - mae: 13.4257 - val_loss: 400.5633 - val_mae: 14.0716 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 353.8576 - mae: 12.6007\n",
      "Epoch 20: val_loss improved from 400.56329 to 372.39197, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 354.0671 - mae: 12.6222 - val_loss: 372.3920 - val_mae: 13.4914 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 333.5917 - mae: 12.1711\n",
      "Epoch 21: val_loss did not improve from 372.39197\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 333.1783 - mae: 12.1774 - val_loss: 386.6026 - val_mae: 13.2840 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 334.9384 - mae: 12.1592\n",
      "Epoch 22: val_loss did not improve from 372.39197\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 334.9227 - mae: 12.1802 - val_loss: 375.6850 - val_mae: 13.0892 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 332.8932 - mae: 12.0559\n",
      "Epoch 23: val_loss improved from 372.39197 to 339.16534, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 332.5251 - mae: 12.0690 - val_loss: 339.1653 - val_mae: 12.7143 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 297.1904 - mae: 11.3788\n",
      "Epoch 24: val_loss did not improve from 339.16534\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 297.6010 - mae: 11.3933 - val_loss: 347.0844 - val_mae: 12.4572 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 307.0780 - mae: 11.5322\n",
      "Epoch 25: val_loss did not improve from 339.16534\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 307.2699 - mae: 11.5584 - val_loss: 344.5549 - val_mae: 12.4663 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 314.4185 - mae: 11.6078\n",
      "Epoch 26: val_loss improved from 339.16534 to 322.47046, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 313.7954 - mae: 11.6120 - val_loss: 322.4705 - val_mae: 12.1464 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 282.7333 - mae: 10.9806\n",
      "Epoch 27: val_loss did not improve from 322.47046\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 282.7306 - mae: 10.9901 - val_loss: 328.4870 - val_mae: 12.0497 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 277.4799 - mae: 10.8512\n",
      "Epoch 28: val_loss did not improve from 322.47046\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 277.2403 - mae: 10.8611 - val_loss: 344.0796 - val_mae: 12.1514 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 291.2222 - mae: 11.0779\n",
      "Epoch 29: val_loss did not improve from 322.47046\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 290.2619 - mae: 11.0766 - val_loss: 335.3509 - val_mae: 12.0542 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 281.6550 - mae: 10.9193\n",
      "Epoch 30: val_loss improved from 322.47046 to 316.23053, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 280.9861 - mae: 10.9210 - val_loss: 316.2305 - val_mae: 11.7608 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 262.7178 - mae: 10.5244\n",
      "Epoch 31: val_loss did not improve from 316.23053\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 262.3235 - mae: 10.5291 - val_loss: 319.6566 - val_mae: 11.6329 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 262.9727 - mae: 10.4576\n",
      "Epoch 32: val_loss did not improve from 316.23053\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 261.9082 - mae: 10.4505 - val_loss: 330.3626 - val_mae: 11.7062 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 265.4165 - mae: 10.4964\n",
      "Epoch 33: val_loss improved from 316.23053 to 291.64755, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 264.6820 - mae: 10.5024 - val_loss: 291.6476 - val_mae: 11.1074 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 244.7660 - mae: 10.0453\n",
      "Epoch 34: val_loss improved from 291.64755 to 277.71051, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 243.4036 - mae: 10.0291 - val_loss: 277.7105 - val_mae: 10.8202 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 244.4079 - mae: 10.0237\n",
      "Epoch 35: val_loss did not improve from 277.71051\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 243.9276 - mae: 10.0241 - val_loss: 546.4915 - val_mae: 15.4878 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 335.6162 - mae: 11.9846\n",
      "Epoch 36: val_loss did not improve from 277.71051\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 334.5834 - mae: 11.9999 - val_loss: 428.7440 - val_mae: 13.6001 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 422.8974 - mae: 13.9458\n",
      "Epoch 37: val_loss did not improve from 277.71051\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 416.3570 - mae: 13.8554 - val_loss: 300.0006 - val_mae: 11.7679 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 347.7849 - mae: 12.3332\n",
      "Epoch 38: val_loss did not improve from 277.71051\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 343.0515 - mae: 12.2643 - val_loss: 295.1767 - val_mae: 11.3908 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 279.7143 - mae: 10.8078\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: val_loss did not improve from 277.71051\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 276.7731 - mae: 10.7628 - val_loss: 392.7319 - val_mae: 12.8792 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 293.3191 - mae: 11.1232\n",
      "Epoch 40: val_loss improved from 277.71051 to 252.68594, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 290.0624 - mae: 11.0930 - val_loss: 252.6859 - val_mae: 10.6007 - learning_rate: 5.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 222.5296 - mae: 9.6143\n",
      "Epoch 41: val_loss improved from 252.68594 to 246.68185, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 221.3585 - mae: 9.5989 - val_loss: 246.6819 - val_mae: 10.2650 - learning_rate: 5.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 201.1694 - mae: 9.2028\n",
      "Epoch 42: val_loss did not improve from 246.68185\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 200.7615 - mae: 9.1944 - val_loss: 272.1274 - val_mae: 10.5486 - learning_rate: 5.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 227.7916 - mae: 9.5764\n",
      "Epoch 43: val_loss did not improve from 246.68185\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - loss: 226.3700 - mae: 9.5644 - val_loss: 248.6394 - val_mae: 10.1835 - learning_rate: 5.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 208.6590 - mae: 9.2664\n",
      "Epoch 44: val_loss improved from 246.68185 to 242.04408, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 207.7462 - mae: 9.2572 - val_loss: 242.0441 - val_mae: 10.0846 - learning_rate: 5.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 193.8312 - mae: 8.9096\n",
      "Epoch 45: val_loss did not improve from 242.04408\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 193.6783 - mae: 8.9136 - val_loss: 270.9422 - val_mae: 10.5081 - learning_rate: 5.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 199.5414 - mae: 8.9844\n",
      "Epoch 46: val_loss did not improve from 242.04408\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 199.1142 - mae: 8.9842 - val_loss: 257.6636 - val_mae: 10.2839 - learning_rate: 5.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 192.0815 - mae: 8.8379\n",
      "Epoch 47: val_loss did not improve from 242.04408\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 191.0337 - mae: 8.8230 - val_loss: 257.4343 - val_mae: 10.2750 - learning_rate: 5.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 190.3093 - mae: 8.6936\n",
      "Epoch 48: val_loss improved from 242.04408 to 239.45593, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 190.1931 - mae: 8.7002 - val_loss: 239.4559 - val_mae: 9.9423 - learning_rate: 5.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 184.7905 - mae: 8.6709\n",
      "Epoch 49: val_loss did not improve from 239.45593\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 184.3652 - mae: 8.6675 - val_loss: 269.8781 - val_mae: 10.4549 - learning_rate: 5.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 182.1698 - mae: 8.5449\n",
      "Epoch 50: val_loss did not improve from 239.45593\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 182.1804 - mae: 8.5554 - val_loss: 275.2370 - val_mae: 10.5224 - learning_rate: 5.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 185.4407 - mae: 8.5834\n",
      "Epoch 51: val_loss improved from 239.45593 to 236.68842, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 185.1197 - mae: 8.5930 - val_loss: 236.6884 - val_mae: 9.8128 - learning_rate: 5.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 182.2508 - mae: 8.6343\n",
      "Epoch 52: val_loss did not improve from 236.68842\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 181.7732 - mae: 8.6338 - val_loss: 264.5273 - val_mae: 10.2794 - learning_rate: 5.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 195.7659 - mae: 8.8645\n",
      "Epoch 53: val_loss did not improve from 236.68842\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 194.6265 - mae: 8.8495 - val_loss: 268.6855 - val_mae: 10.2041 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 184.6920 - mae: 8.6218\n",
      "Epoch 54: val_loss did not improve from 236.68842\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 183.7119 - mae: 8.6094 - val_loss: 272.7829 - val_mae: 10.2200 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 183.6508 - mae: 8.6462\n",
      "Epoch 55: val_loss did not improve from 236.68842\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 182.6014 - mae: 8.6289 - val_loss: 290.1769 - val_mae: 10.5065 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 191.2145 - mae: 8.7636\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 56: val_loss did not improve from 236.68842\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 189.8989 - mae: 8.7449 - val_loss: 293.9658 - val_mae: 10.7002 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 191.4207 - mae: 8.7022\n",
      "Epoch 57: val_loss improved from 236.68842 to 233.38150, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 189.9575 - mae: 8.6830 - val_loss: 233.3815 - val_mae: 9.4802 - learning_rate: 2.5000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 162.2609 - mae: 8.1998\n",
      "Epoch 58: val_loss did not improve from 233.38150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 161.8757 - mae: 8.1914 - val_loss: 271.9371 - val_mae: 10.1773 - learning_rate: 2.5000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 182.2610 - mae: 8.5830\n",
      "Epoch 59: val_loss did not improve from 233.38150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 180.7224 - mae: 8.5547 - val_loss: 238.2863 - val_mae: 9.5073 - learning_rate: 2.5000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 163.1457 - mae: 8.2415\n",
      "Epoch 60: val_loss did not improve from 233.38150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 162.3015 - mae: 8.2224 - val_loss: 259.0159 - val_mae: 9.9054 - learning_rate: 2.5000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 171.9105 - mae: 8.3258\n",
      "Epoch 61: val_loss did not improve from 233.38150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 170.9025 - mae: 8.3133 - val_loss: 240.8579 - val_mae: 9.5569 - learning_rate: 2.5000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 173.6378 - mae: 8.3255\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: val_loss did not improve from 233.38150\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 172.3364 - mae: 8.3016 - val_loss: 239.1443 - val_mae: 9.5193 - learning_rate: 2.5000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 153.9022 - mae: 7.8729\n",
      "Epoch 63: val_loss improved from 233.38150 to 232.90488, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 153.4447 - mae: 7.8678 - val_loss: 232.9049 - val_mae: 9.4131 - learning_rate: 1.2500e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 157.5078 - mae: 7.9840\n",
      "Epoch 64: val_loss did not improve from 232.90488\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 157.4126 - mae: 7.9872 - val_loss: 243.3227 - val_mae: 9.6001 - learning_rate: 1.2500e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 161.1739 - mae: 8.0241\n",
      "Epoch 65: val_loss did not improve from 232.90488\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 160.7858 - mae: 8.0210 - val_loss: 237.5963 - val_mae: 9.4823 - learning_rate: 1.2500e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 158.8023 - mae: 8.0449\n",
      "Epoch 66: val_loss improved from 232.90488 to 224.78763, saving model to /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/models/transformer_P012.keras\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 158.2300 - mae: 8.0390 - val_loss: 224.7876 - val_mae: 9.2508 - learning_rate: 1.2500e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 153.2419 - mae: 7.8994\n",
      "Epoch 67: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 153.4639 - mae: 7.9096 - val_loss: 240.3059 - val_mae: 9.5286 - learning_rate: 1.2500e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 160.2172 - mae: 8.0239\n",
      "Epoch 68: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 159.4602 - mae: 8.0152 - val_loss: 231.5688 - val_mae: 9.3731 - learning_rate: 1.2500e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 156.3046 - mae: 7.9419\n",
      "Epoch 69: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 156.0849 - mae: 7.9429 - val_loss: 224.9928 - val_mae: 9.2547 - learning_rate: 1.2500e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 157.2091 - mae: 7.9464\n",
      "Epoch 70: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 156.5733 - mae: 7.9395 - val_loss: 244.8520 - val_mae: 9.6054 - learning_rate: 1.2500e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 169.8017 - mae: 8.2059\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 71: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 168.4526 - mae: 8.1815 - val_loss: 235.1205 - val_mae: 9.4294 - learning_rate: 1.2500e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 159.6452 - mae: 8.0200\n",
      "Epoch 72: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 158.5441 - mae: 7.9985 - val_loss: 232.2753 - val_mae: 9.3827 - learning_rate: 6.2500e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 151.0684 - mae: 7.8097\n",
      "Epoch 73: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 150.4895 - mae: 7.8009 - val_loss: 234.4679 - val_mae: 9.4316 - learning_rate: 6.2500e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 156.1827 - mae: 7.9078\n",
      "Epoch 74: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 155.3511 - mae: 7.8942 - val_loss: 237.4711 - val_mae: 9.4833 - learning_rate: 6.2500e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 166.4173 - mae: 8.0915\n",
      "Epoch 75: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 165.0405 - mae: 8.0664 - val_loss: 233.0695 - val_mae: 9.3984 - learning_rate: 6.2500e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 157.7582 - mae: 7.9376\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 76: val_loss did not improve from 224.78763\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 157.2591 - mae: 7.9343 - val_loss: 229.3775 - val_mae: 9.3336 - learning_rate: 6.2500e-05\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "\u001b[32m2025-04-13 16:05:38.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mTraining finished.\u001b[0m\n",
      "+------------------+---------+---------+\n",
      "| Model            |    loss |     mae |\n",
      "+==================+=========+=========+\n",
      "| transformer_P012 | 393.614 | 14.0715 |\n",
      "+------------------+---------+---------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 393.6141052246094, 'mae': 14.071540832519531}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model, model_name = build_lstm_model(input_shape=input_shape, test_id=test_ids, padding_value=PADDING_VALUE)\n",
    "\n",
    "# model, model_name = build_mlp_model(input_shape=input_shape, test_id=test_ids, padding_value=PADDING_VALUE)\n",
    "\n",
    "model, model_name = build_transformer_model(input_shape=input_shape, test_id=test_ids, padding_value=PADDING_VALUE)\n",
    "\n",
    "# model, model_name = build_gru_model(input_shape=input_shape, test_id=test_ids, padding_value=PADDING_VALUE)\n",
    "\n",
    "\n",
    "train_model(model=model, train_ds=train_ds, val_ds=val_ds, model_name=model_name, epochs=100)\n",
    "evaluate_model(model=model, test_ds=test_ds, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-13 16:05:38.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mStarting prediction visualization for 1 test participants using model 'transformer_P012'.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:38.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mNo normalization statistics provided. Using raw spectrogram data.\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:38.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mVisualizing predictions for participant P012...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:38.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 1/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:44.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec1.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:44.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 2/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:46.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec2.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:46.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 3/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:48.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec3.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:48.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 4/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:51.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec4.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:51.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 5/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:53.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec5.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:53.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 6/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:55.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec6.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:55.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 7/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:57.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec7.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:57.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 8/8 for P012 left...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:59.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_left_rec8.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:05:59.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 1/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:01.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec1.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:01.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 2/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:03.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec2.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:03.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 3/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:05.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec3.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:05.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 4/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:07.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec4.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:07.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 5/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec5.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 6/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:11.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec6.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:11.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 7/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:13.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec7.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:13.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m  Processing recording 8/8 for P012 right...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:14.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m293\u001b[0m - \u001b[1m  Saved prediction plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_right_rec8.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:14.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mplot_overlay_predictions\u001b[0m:\u001b[36m369\u001b[0m - \u001b[1mGenerating combined overlay plots for participant P012...\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:15.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mplot_overlay_predictions\u001b[0m:\u001b[36m506\u001b[0m - \u001b[1m  Saved absolute time overlay plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_overlay_absolute_time.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:15.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mplot_overlay_predictions\u001b[0m:\u001b[36m570\u001b[0m - \u001b[1m  Saved normalized time overlay plot to: /home/lg519/Projects/Muscle_Fatigue_Research/emg_fatigue/reports/figures/P012/transformer_P012_overlay_normalized_time.png\u001b[0m\n",
      "\u001b[32m2025-04-13 16:06:15.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36memg_fatigue.plots.visualize_model_predictions\u001b[0m:\u001b[36mvisualize_model_predictions\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mFinished prediction visualization for model 'transformer_P012'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "visualize_model_predictions(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    processed_data=processed_data,\n",
    "    test_participant_ids=test_ids,\n",
    "    input_shape=input_shape,\n",
    "    norm_mean=norm_mean,\n",
    "    norm_std=norm_std\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg-fatigue-YbMeuwX9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
